equal_weight_port = equal_weight_port + equal_weight_port * returns
bond_heavy_port = bond_heavy_port + bond_heavy_port * returns
foreign_heavy_port = foreign_heavy_port + foreign_heavy_port * returns
# Record the wealths for each portfolio at that point in time
equal_weight_wealths[simulation_num,day_num] = sum(equal_weight_port)
bondy_heavy_wealths[simulation_num,day_num] = sum(bond_heavy_port)
foreign_heavy_wealths[simulation_num,day_num] = sum(foreign_heavy_port)
# Re balance each portfolio
equal_weight_port = sum(equal_weight_port) * portfolio_weights$allocation_equal
bond_heavy_port = sum(bond_heavy_port) * portfolio_weights$allocation_bond_heavy
foreign_heavy_port = sum(foreign_heavy_port) * portfolio_weights$allocation_foreign
}
}
# Create an data frame containing info for all portfolios. This makes plotting easier with ggplot.
equal_weight_wealths$Type = 'Equal Weight'
foreign_heavy_wealths$Type = 'Foreign Heavy'
bondy_heavy_wealths$Type = 'Bondy Heavy'
all_ending_wealths = rbind(equal_weight_wealths,bondy_heavy_wealths)
all_ending_wealths = rbind(all_ending_wealths,foreign_heavy_wealths)
all_ending_wealths %>%  ggplot(aes(x=X20)) + geom_histogram(fill='white', color='black', bins = 50) + facet_grid(Type ~.,scales = 'free') + geom_vline(xintercept = 100000, size=1,color='blue')+ scale_x_continuous(labels = scales::dollar_format()) + labs(title='Distribution of Ending Wealths By Portfolio')
# Var
all_ending_wealths$profit = all_ending_wealths$X20 - initial_capital
ggplot(all_ending_wealths,aes(profit)) + geom_histogram(fill='white', color='black', bins = 50) + facet_grid(Type ~.,scales = 'free') + scale_x_continuous(labels = scales::dollar_format()) + labs(title='Distribution of Ending Profits By Portfolio')
summary_stats = all_ending_wealths %>% group_by(Type) %>% summarise(VAR_.05 = quantile(profit,prob=.05), Minimum_Profit = min(profit),Max_Profit = max(profit), Average_Profit= mean(profit), MAD = mad(profit), Range = max(profit)-min(profit))
knitr::kable(summary_stats,caption = "Summary Stats for Portfolio Profits", digits = 2,format.args = list(big.mark = ",",
scientific = FALSE))
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
set.seed(42)
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
library(mosaic)
library(quantmod)
library(foreach)
# Load data from web
# Get ETs
my_etfs = c("ARKK", "SDY", "GOVT",'BNO','EWJ','XLF','MCHI','HYG')
etf_count = length(my_etfs) # Need this later
# 5 years of data
getSymbols(my_etfs,from='2016-8-1')
# We want to look at adjusted values only
for(ticker in my_etfs) {
expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
eval(parse(text=expr))
}
my_etfs_adjusted = paste(my_etfs,'a',sep = '')
all_returns = cbind( ClCl(ARKKa),
ClCl(SDYa),
ClCl(XLFa),
ClCl(GOVTa),
ClCl(HYGa),
ClCl(EWJa),
ClCl(MCHIa),
ClCl(BNOa))
all_returns = as.matrix(na.omit(all_returns))
# Create 3 portfolios.
# Equal weighted /no opinion portfolio
allocation_equal = rep(1/etf_count,etf_count)
# Create bond allocation. 80% in two bond funds. Equal weight placed in the remaining
bond_allocation = .8
non_bond = (1-bond_allocation)/6
allocation_bond_heavy = rep(non_bond,etf_count)
allocation_bond_heavy[c(4,5)] = bond_allocation/2
# Foreign Heavy
foreign_allocation = .8
non_foreign = (1-foreign_allocation)/6
allocation_foreign = rep(non_foreign,etf_count)
allocation_foreign[c(6,7)] = foreign_allocation/2
# Compile three portfolios in a matrix
portfolio_weights = as.data.frame(cbind(allocation_equal,allocation_bond_heavy,allocation_foreign))
# Make sure each of the allocations sum to one
colSums(portfolio_weights) == 1
# Run the simulation!
# Simulation Parameters
initial_capital = 100000
days_in_simulation = 20
simulation_count = 10000
# all_ending_wealths = rep(0,simulation_count) # matrix to store ending wealths
# Create 3 matrices to store the daily wealths of each portfolio
# These will be 10,000 X 20 dim matrices
equal_weight_wealths = data.frame(matrix(rep(0,days_in_simulation* simulation_count),nrow=simulation_count,ncol=days_in_simulation))
bondy_heavy_wealths = data.frame(matrix(rep(0,days_in_simulation* simulation_count),nrow=simulation_count,ncol=days_in_simulation))
foreign_heavy_wealths = data.frame(matrix(rep(0,days_in_simulation* simulation_count),nrow=simulation_count,ncol=days_in_simulation))
for (simulation_num in 1:simulation_count) {
# 3 Vectors containing the dollar value holding of each ETF
equal_weight_port = portfolio_weights$allocation_equal * initial_capital
bond_heavy_port = portfolio_weights$allocation_bond_heavy * initial_capital
foreign_heavy_port = portfolio_weights$allocation_foreign * initial_capital
for (day_num in 1:days_in_simulation) {
returns = resample(all_returns,1) # Sample returns
# Calculate ending wealths after each day
equal_weight_port = equal_weight_port + equal_weight_port * returns
bond_heavy_port = bond_heavy_port + bond_heavy_port * returns
foreign_heavy_port = foreign_heavy_port + foreign_heavy_port * returns
# Record the wealths for each portfolio at that point in time
equal_weight_wealths[simulation_num,day_num] = sum(equal_weight_port)
bondy_heavy_wealths[simulation_num,day_num] = sum(bond_heavy_port)
foreign_heavy_wealths[simulation_num,day_num] = sum(foreign_heavy_port)
# Re balance each portfolio
equal_weight_port = sum(equal_weight_port) * portfolio_weights$allocation_equal
bond_heavy_port = sum(bond_heavy_port) * portfolio_weights$allocation_bond_heavy
foreign_heavy_port = sum(foreign_heavy_port) * portfolio_weights$allocation_foreign
}
}
# Create an data frame containing info for all portfolios. This makes plotting easier with ggplot.
equal_weight_wealths$Type = 'Equal Weight'
foreign_heavy_wealths$Type = 'Foreign Heavy'
bondy_heavy_wealths$Type = 'Bondy Heavy'
all_ending_wealths = rbind(equal_weight_wealths,bondy_heavy_wealths)
all_ending_wealths = rbind(all_ending_wealths,foreign_heavy_wealths)
# # Create an data frame containing info for all portfolios. This makes plotting easier with ggplot.
# equal_weight_wealths$Type = 'Equal Weight'
# foreign_heavy_wealths$Type = 'Foreign Heavy'
# bondy_heavy_wealths$Type = 'Bondy Heavy'
#
# all_ending_wealths = rbind(equal_weight_wealths,bondy_heavy_wealths)
# all_ending_wealths = rbind(all_ending_wealths,foreign_heavy_wealths)
all_ending_wealths %>%  ggplot(aes(x=X20)) + geom_histogram(fill='white', color='black', bins = 50) + facet_grid(Type ~.,scales = 'free') + geom_vline(xintercept = 100000, size=1,color='blue')+ scale_x_continuous(labels = scales::dollar_format()) + labs(title='Distribution of Ending Wealths By Portfolio')
# Var
all_ending_wealths$profit = all_ending_wealths$X20 - initial_capital
ggplot(all_ending_wealths,aes(profit)) + geom_histogram(fill='white', color='black', bins = 50) + facet_grid(Type ~.,scales = 'free') + scale_x_continuous(labels = scales::dollar_format()) + labs(title='Distribution of Ending Profits By Portfolio')
summary_stats = all_ending_wealths %>% group_by(Type) %>% summarise(VAR_.05 = quantile(profit,prob=.05), Minimum_Profit = min(profit),Max_Profit = max(profit), Average_Profit= mean(profit), MAD = mad(profit), Range = max(profit)-min(profit))
knitr::kable(summary_stats,caption = "Summary Stats for Portfolio Profits", digits = 2,format.args = list(big.mark = ",",
scientific = FALSE))
# Getting the wealth paths for each portfolio for the worst profit.
minports =  data.frame(all_ending_wealths %>%  group_by(Type) %>% filter(profit == min(profit)))
wealth_paths = data.frame(t(minports %>% select(-Type,-profit)))
colnames(wealth_paths) = c('Bond_Heavy', 'Equal_Weight', 'Foreign_Heavy')
wealth_paths$Day = 1:20
colors = c("Bond_Heavy" = "Green", "Equal_Weight" = "Blue", "Foreign_Heavy" = "Red")
ggplot(wealth_paths,aes(x=Day)) + geom_line(aes(y=Bond_Heavy, color='Bond_Heavy'),size=1.5) + geom_line(aes(y=Equal_Weight ,color='Equal_Weight'),size=1.5) + geom_line(aes(y=Foreign_Heavy,color='Foreign_Heavy'),size=1.5) + scale_y_continuous(labels = scales::dollar_format()) + labs(x='Day', y='Portfolio Paths', color='Legend', title = 'Worst Performing Periods By Portfolio')
# Getting the wealth paths for each portfolio for the worst profit.
minports =  data.frame(all_ending_wealths %>%  group_by(Type) %>% filter(profit == min(profit)))
wealth_paths = data.frame(t(minports %>% select(-Type,-profit)))
colnames(wealth_paths) = c('Bond_Heavy', 'Equal_Weight', 'Foreign_Heavy')
wealth_paths$Day = 1:20
colors = c("Bond_Heavy" = "Green", "Equal_Weight" = "Blue", "Foreign_Heavy" = "Red")
ggplot(wealth_paths,aes(x=Day)) + geom_line(aes(y=Bond_Heavy, color='Bond_Heavy'),size=1.5) + geom_line(aes(y=Equal_Weight ,color='Equal_Weight'),size=1.5) + geom_line(aes(y=Foreign_Heavy,color='Foreign_Heavy'),size=1.5) + scale_y_continuous(labels = scales::dollar_format()) + labs(x='Day', y='Portfolio Paths', color='Legend', title = 'Worst Performing Periods By Portfolio')  + scale_color_manual(values = colors)
View(welath_paths)
data.frame(all_ending_wealths %>%  group_by(Type) %>% filter(profit == min(profit)))
# Getting the wealth paths for each portfolio for the worst profit.
minports =  data.frame(all_ending_wealths %>%  group_by(Type) %>% filter(profit == min(profit)))
wealth_paths = data.frame(t(minports %>% select(-Type,-profit)))
colnames(wealth_paths) = c('Equal_Weight','Bond_Heavy', 'Foreign_Heavy')
wealth_paths$Day = 1:20
colors = c("Bond_Heavy" = "Green", "Equal_Weight" = "Blue", "Foreign_Heavy" = "Red")
ggplot(wealth_paths,aes(x=Day)) + geom_line(aes(y=Bond_Heavy, color='Bond_Heavy'),size=1.5) + geom_line(aes(y=Equal_Weight ,color='Equal_Weight'),size=1.5) + geom_line(aes(y=Foreign_Heavy,color='Foreign_Heavy'),size=1.5) + scale_y_continuous(labels = scales::dollar_format()) + labs(x='Day', y='Portfolio Paths', color='Legend', title = 'Worst Performing Periods By Portfolio')  + scale_color_manual(values = colors)
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
# Read in the data
greenbuildings <- read_csv("greenbuildings.csv")
greenbuildings = greenbuildings %>% select(-CS_PropertyID,-cluster) # Get rid of useless columns
# Convert categorical to factors and change binaries into 'Yes' and 'No'
data_plotting = greenbuildings
for (col_name in colnames(data_plotting)) {
data = data_plotting[[col_name]]
uniques = length(unique(data))
if ( uniques <=2) {
data = ifelse(data == 1,'Yes','No')
data_plotting[[col_name]] <- factor(data)
}
}
# We want to understand what's going on with those data points he's scrubbing.
# summary(greenbuildings)
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# I believe it could be valid to remove these, because we don't really care much about
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
# Only 215 data points
# summary(greenbuildings)
# summary(low_occupany)
# only getting rid of 1 green rating data point?
# sum(low_occupany$green_rating)
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
rent_median = median(greenbuildings$Rent)
rent_mean = mean(greenbuildings$Rent)
rent_skew = skewness(greenbuildings$Rent)
abline(v=rent_median,lwd=2,col='blue')
abline(v=rent_mean,lwd=2,col='red')
text(100,1000, 'Mean = 28.42 \n Median = 25.16 \n Skew = 3.49')
ggplot(data_plotting,aes(x=cluster_rent,y=Rent)) + geom_point() + stat_smooth(method=lm,level=.95) + labs(title = 'Positive Association Between Rent of Cluster and Rent')
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
# Read in the data
greenbuildings <- read_csv("greenbuildings.csv")
greenbuildings = greenbuildings %>% select(-CS_PropertyID,-cluster) # Get rid of useless columns
# Convert categorical to factors and change binaries into 'Yes' and 'No'
data_plotting = greenbuildings
for (col_name in colnames(data_plotting)) {
data = data_plotting[[col_name]]
uniques = length(unique(data))
if ( uniques <=2) {
data = ifelse(data == 1,'Yes','No')
data_plotting[[col_name]] <- factor(data)
}
}
# We want to understand what's going on with those data points he's scrubbing.
# summary(greenbuildings)
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# I believe it could be valid to remove these, because we don't really care much about
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
# Only 215 data points
# summary(greenbuildings)
# summary(low_occupany)
# only getting rid of 1 green rating data point?
# sum(low_occupany$green_rating)
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
rent_median = median(greenbuildings$Rent)
rent_mean = mean(greenbuildings$Rent)
rent_skew = skewness(greenbuildings$Rent)
abline(v=rent_median,lwd=2,col='blue')
abline(v=rent_mean,lwd=2,col='red')
text(100,1000, 'Mean = 28.42 \n Median = 25.16 \n Skew = 3.49')
data_plotting %>% group_by(green_rating) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot(aes(x=green_rating,y=Median_Rent,fill=green_rating)) +
geom_col() + geom_text(aes(label=Median_Rent),vjust=1.5,color='white') + labs(title = 'Median Rent by Greeness') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_no_nas = na.omit(greenbuildings) # remove na's from employment
# data_no_employ = greenbuildings %>% select(-empl_gr)
# ggcorrplot(cor(data_no_employ), hc.order = TRUE, outline.color = "white")
corry_matrix = cor(data_no_nas)
ggcorrplot(corry_matrix, hc.order = TRUE, outline.color = "white") + labs(title='Correlation Matrix')
ggplot(data_plotting) + geom_boxplot(aes(x=green_rating,y=age, fill=green_rating)) + labs(title = 'Age Distribution by Greenness')
med_age = median(data_plotting$age)
data_plotting <- data_plotting %>% mutate(younger = ifelse(age <= med_age,'Yes','No'))
# data_plotting$newer = factor(data_plotting$younger)
data_plotting %>% group_by(younger) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot() +
geom_col(aes(x=younger,y=Median_Rent,fill=younger)) + labs(title = 'Median Rent by Age') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_plotting %>% group_by(green_rating,younger) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=younger,y=Median_Rent,fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Age & Greenness') + scale_y_continuous(breaks=seq(0,30,5))
green_only = data_plotting %>% filter(green_rating == "Yes")
ggplot(data=green_only, aes(x=class_a, fill=class_a)) + geom_bar(color='black') + labs(title = 'Count of Class A within Greenness')
data_plotting %>% group_by(green_rating,class_a) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=class_a,y=Median_Rent, fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Class A & Greenness')  + scale_y_continuous(breaks=seq(0,30,5))
ggplot(data_plotting,aes(x=cluster_rent,y=Rent)) + geom_point() + stat_smooth(method=lm,level=.95) + labs(title = 'Positive Association Between Rent of Cluster and Rent')
model_data = greenbuildings %>% select(-total_dd_07) # Remove total because it is just a combination of two other vars.
# model_data = greenbuildings %>% select(-cd_total_07,-hd_total07)
lm_model = lm(Rent~.,data=model_data)
summary(lm_model)
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
set.seed(42)
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
library(mosaic)
library(quantmod)
library(foreach)
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
# Read in the data
greenbuildings <- read_csv("greenbuildings.csv")
greenbuildings = greenbuildings %>% select(-CS_PropertyID,-cluster) # Get rid of useless columns
# Convert categorical to factors and change binaries into 'Yes' and 'No'
data_plotting = greenbuildings
for (col_name in colnames(data_plotting)) {
data = data_plotting[[col_name]]
uniques = length(unique(data))
if ( uniques <=2) {
data = ifelse(data == 1,'Yes','No')
data_plotting[[col_name]] <- factor(data)
}
}
# We want to understand what's going on with those data points he's scrubbing.
# summary(greenbuildings)
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# I believe it could be valid to remove these, because we don't really care much about
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
# Only 215 data points
# summary(greenbuildings)
# summary(low_occupany)
# only getting rid of 1 green rating data point?
# sum(low_occupany$green_rating)
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
rent_median = median(greenbuildings$Rent)
rent_mean = mean(greenbuildings$Rent)
rent_skew = skewness(greenbuildings$Rent)
abline(v=rent_median,lwd=2,col='blue')
abline(v=rent_mean,lwd=2,col='red')
text(100,1000, 'Mean = 28.42 \n Median = 25.16 \n Skew = 3.49')
data_plotting %>% group_by(green_rating) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot(aes(x=green_rating,y=Median_Rent,fill=green_rating)) +
geom_col() + geom_text(aes(label=Median_Rent),vjust=1.5,color='white') + labs(title = 'Median Rent by Greeness') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_no_nas = na.omit(greenbuildings) # remove na's from employment
# data_no_employ = greenbuildings %>% select(-empl_gr)
# ggcorrplot(cor(data_no_employ), hc.order = TRUE, outline.color = "white")
corry_matrix = cor(data_no_nas)
ggcorrplot(corry_matrix, hc.order = TRUE, outline.color = "white") + labs(title='Correlation Matrix')
ggplot(data_plotting) + geom_boxplot(aes(x=green_rating,y=age, fill=green_rating)) + labs(title = 'Age Distribution by Greenness')
med_age = median(data_plotting$age)
data_plotting <- data_plotting %>% mutate(younger = ifelse(age <= med_age,'Yes','No'))
# data_plotting$newer = factor(data_plotting$younger)
data_plotting %>% group_by(younger) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot() +
geom_col(aes(x=younger,y=Median_Rent,fill=younger)) + labs(title = 'Median Rent by Age') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_plotting %>% group_by(green_rating,younger) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=younger,y=Median_Rent,fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Age & Greenness') + scale_y_continuous(breaks=seq(0,30,5))
green_only = data_plotting %>% filter(green_rating == "Yes")
ggplot(data=green_only, aes(x=class_a, fill=class_a)) + geom_bar(color='black') + labs(title = 'Count of Class A within Greenness')
data_plotting %>% group_by(green_rating,class_a) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=class_a,y=Median_Rent, fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Class A & Greenness')  + scale_y_continuous(breaks=seq(0,30,5))
ggplot(data_plotting,aes(x=cluster_rent,y=Rent)) + geom_point() + stat_smooth(method=lm,level=.95) + labs(title = 'Positive Association Between Rent of Cluster and Rent')
model_data = greenbuildings %>% select(-total_dd_07) # Remove total because it is just a combination of two other vars.
# model_data = greenbuildings %>% select(-cd_total_07,-hd_total07)
lm_model = lm(Rent~.,data=model_data)
summary(lm_model)
# We want to understand what's going on with those data points he's scrubbing.
# summary(greenbuildings)
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
boxplot(low_occupany$Rent)
View(low_occupany)
hist(low_occupany$leasing_rate)
200/7894
View(portfolio_weights)
View(wealth_paths)
# We want to understand what's going on with those data points he's scrubbing.
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# I believe it could be valid to remove these, because we don't really care much about
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
# Only 215 data points
summary(greenbuildings)
summary(low_occupany)
# only getting rid of 1 green rating data point?
# sum(low_occupany$green_rating)
# only getting rid of 1 green rating data point?
dim(low_occupany$green_rating)
# only getting rid of 1 green rating data point?
dim(low_occupany)
215/7894
# We want to understand what's going on with those data points he's scrubbing.
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# I believe it could be valid to remove these, because we don't really care much about
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
# Only 215 data points
# summary(greenbuildings)
# summary(low_occupany)
# dim(low_occupany)
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
# Read in the data
greenbuildings <- read_csv("greenbuildings.csv")
greenbuildings = greenbuildings %>% select(-CS_PropertyID,-cluster) # Get rid of useless columns
# Convert categorical to factors and change binaries into 'Yes' and 'No'
data_plotting = greenbuildings
for (col_name in colnames(data_plotting)) {
data = data_plotting[[col_name]]
uniques = length(unique(data))
if ( uniques <=2) {
data = ifelse(data == 1,'Yes','No')
data_plotting[[col_name]] <- factor(data)
}
}
# We want to understand what's going on with those data points he's scrubbing.
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
summary(greenbuildings)
summary(low_occupany)
dim(low_occupany)
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
rent_median = median(greenbuildings$Rent)
rent_mean = mean(greenbuildings$Rent)
rent_skew = skewness(greenbuildings$Rent)
abline(v=rent_median,lwd=2,col='blue')
abline(v=rent_mean,lwd=2,col='red')
text(100,1000, 'Mean = 28.42 \n Median = 25.16 \n Skew = 3.49')
data_plotting %>% group_by(green_rating) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot(aes(x=green_rating,y=Median_Rent,fill=green_rating)) +
geom_col() + geom_text(aes(label=Median_Rent),vjust=1.5,color='white') + labs(title = 'Median Rent by Greeness') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_no_nas = na.omit(greenbuildings) # remove na's from employment
# data_no_employ = greenbuildings %>% select(-empl_gr)
# ggcorrplot(cor(data_no_employ), hc.order = TRUE, outline.color = "white")
corry_matrix = cor(data_no_nas)
ggcorrplot(corry_matrix, hc.order = TRUE, outline.color = "white") + labs(title='Correlation Matrix')
ggplot(data_plotting) + geom_boxplot(aes(x=green_rating,y=age, fill=green_rating)) + labs(title = 'Age Distribution by Greenness')
med_age = median(data_plotting$age)
data_plotting <- data_plotting %>% mutate(younger = ifelse(age <= med_age,'Yes','No'))
# data_plotting$newer = factor(data_plotting$younger)
data_plotting %>% group_by(younger) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot() +
geom_col(aes(x=younger,y=Median_Rent,fill=younger)) + labs(title = 'Median Rent by Age') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_plotting %>% group_by(green_rating,younger) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=younger,y=Median_Rent,fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Age & Greenness') + scale_y_continuous(breaks=seq(0,30,5))
green_only = data_plotting %>% filter(green_rating == "Yes")
ggplot(data=green_only, aes(x=class_a, fill=class_a)) + geom_bar(color='black') + labs(title = 'Count of Class A within Greenness')
data_plotting %>% group_by(green_rating,class_a) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=class_a,y=Median_Rent, fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Class A & Greenness')  + scale_y_continuous(breaks=seq(0,30,5))
knitr::opts_chunk$set(echo = FALSE)
# output:
#   md_document:
#     variant: markdown_github
# Load libraries
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
library(moments)
# Read in the data
greenbuildings <- read_csv("greenbuildings.csv")
greenbuildings = greenbuildings %>% select(-CS_PropertyID,-cluster) # Get rid of useless columns
# Convert categorical to factors and change binaries into 'Yes' and 'No'
data_plotting = greenbuildings
for (col_name in colnames(data_plotting)) {
data = data_plotting[[col_name]]
uniques = length(unique(data))
if ( uniques <=2) {
data = ifelse(data == 1,'Yes','No')
data_plotting[[col_name]] <- factor(data)
}
}
# We want to understand what's going on with those data points he's scrubbing.
low_occupany = greenbuildings %>% filter(leasing_rate < 10)
other = greenbuildings %>% filter(leasing_rate >= 10)
# None of the values seem too out of control to me. Just that they may be a bit older buildings.
# Less than 10 seems pretty arbitrary though. So I'm leaning towards keeping it all.
# Might be that those buildings just get rented at weird times of the year or something.
# Either way, removing those data points or keeping them doesn't seem to change our conclusion much
summary(greenbuildings)
summary(low_occupany)
dim(low_occupany)
hist(greenbuildings$Rent, breaks = 50,xlab='Rent',main='Histogram of Rent')
rent_median = median(greenbuildings$Rent)
rent_mean = mean(greenbuildings$Rent)
rent_skew = skewness(greenbuildings$Rent)
abline(v=rent_median,lwd=2,col='blue')
abline(v=rent_mean,lwd=2,col='red')
text(100,1000, 'Mean = 28.42 \n Median = 25.16 \n Skew = 3.49')
data_plotting %>% group_by(green_rating) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot(aes(x=green_rating,y=Median_Rent,fill=green_rating)) +
geom_col() + geom_text(aes(label=Median_Rent),vjust=1.5,color='white') + labs(title = 'Median Rent by Greeness') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_no_nas = na.omit(greenbuildings) # remove na's from employment
# data_no_employ = greenbuildings %>% select(-empl_gr)
# ggcorrplot(cor(data_no_employ), hc.order = TRUE, outline.color = "white")
corry_matrix = cor(data_no_nas)
ggcorrplot(corry_matrix, hc.order = TRUE, outline.color = "white") + labs(title='Correlation Matrix')
ggplot(data_plotting) + geom_boxplot(aes(x=green_rating,y=age, fill=green_rating)) + labs(title = 'Age Distribution by Greenness')
med_age = median(data_plotting$age)
data_plotting <- data_plotting %>% mutate(younger = ifelse(age <= med_age,'Yes','No'))
# data_plotting$newer = factor(data_plotting$younger)
data_plotting %>% group_by(younger) %>%  summarise(Median_Rent = median(Rent)) %>% ggplot() +
geom_col(aes(x=younger,y=Median_Rent,fill=younger)) + labs(title = 'Median Rent by Age') + coord_cartesian(ylim=c(0,30)) + scale_y_continuous(breaks=seq(0,30,5))
data_plotting %>% group_by(green_rating,younger) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=younger,y=Median_Rent,fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Age & Greenness') + scale_y_continuous(breaks=seq(0,30,5))
green_only = data_plotting %>% filter(green_rating == "Yes")
ggplot(data=green_only, aes(x=class_a, fill=class_a)) + geom_bar(color='black') + labs(title = 'Count of Class A within Greenness')
data_plotting %>% group_by(green_rating,class_a) %>%  summarise(Median_Rent = median(Rent), count = n()) %>% ggplot(aes(x=class_a,y=Median_Rent, fill=green_rating)) + geom_col(position = 'dodge',color='black') + labs(title = 'Median Rent by Class A & Greenness')  + scale_y_continuous(breaks=seq(0,30,5))
data_plotting %>% group_by(LEED,Energystar)
data_plotting %>% group_by(LEED,Energystar) %>% summarise(Median_Rent = median(Rent))
new_fram = data_plotting %>% filter(LEED == 'Yes')
new_fram
new_fram = data_plotting %>% filter(LEED == 'Yes', Energystar == 'Yes')
new_fram
new_fram = data_plotting %>% filter(LEED == 'Yes'|Energystar == 'Yes')
new_fram
sum(greenbuildings$LEED)
sum(greenbuildings$Energystar)
model_data = greenbuildings %>% select(-total_dd_07) # Remove total because it is just a combination of two other vars.
# model_data = greenbuildings %>% select(-cd_total_07,-hd_total07)
lm_model = lm(Rent~.,data=model_data)
summary(lm_model)
setwd("C:/Users/User/OneDrive/Desktop/Machine Learning/Machine-Learning")
